#!/bin/bash

# python-link-harvester
# Autor: Leonardo Bruno
# Contato: souzalb@proton.me
# Vers√£o: 1.0
# Data: 30/06/2025

# Verifica se o curl est√° instalado
if ! command -v curl &> /dev/null; then
    echo "‚ùå Erro: O comando 'curl' n√£o est√° instalado."
    echo "Por favor instale o curl para continuar:"
    echo ""
    echo "üì¶ Para sistemas baseados em Debian/Ubuntu:"
    echo "  sudo apt-get install curl"
    echo ""
    echo "üì¶ Para sistemas baseados em RHEL/CentOS:"
    echo "  sudo yum install curl"
    echo ""
    echo "üì¶ Para sistemas baseados em Arch:"
    echo "  sudo pacman -S curl"
    echo ""
    echo "üì¶ Para macOS (via Homebrew):"
    echo "  brew install curl"
    exit 1
fi

# URL base para downloads do c√≥digo fonte do Python
URL_BASE="https://www.python.org/downloads/source/"

# Extens√£o do arquivo desejado (c√≥digo fonte compactado)
EXTENSION="tar.xz"

# Nome do arquivo de sa√≠da para os links
OUTPUT_FILE="link-python.txt"

# Limpar o arquivo de sa√≠da (cria novo ou sobrescreve existente)
> "$OUTPUT_FILE"

# Mensagens iniciais para o usu√°rio
echo "üöÄ Iniciando busca em: $URL_BASE"
echo "üîç Procurando por arquivos .${EXTENSION}"
echo "‚è≥ Aguarde alguns instantes..."
echo "üìÅ Processando: ${URL_BASE}"

temp_links=$(mktemp)
temp_sorted=$(mktemp)

# Coletar links usando curl
# -s: Modo silencioso (sem progresso)
# -L: Segue redirecionamentos
# --compressed : Habilita a compacta√ß√£o de dados na transfer√™ncia
# Extrai todos os links da p√°gina que terminam com a extens√£o desejada
curl -s --compressed -L "$URL_BASE" | grep -oP 'href="\K[^"]*\.tar\.xz' | sort -u > "$temp_links"

# Faz a contagem dos links encontrados
total_files=$(wc -l < "$temp_links")

# Processar cada link para extrair a vers√£o do Python
while IFS= read -r url; do
    # Normaliza URLs relativas para absolutas
    if [[ $url == /* ]]; then
        url="https://www.python.org$url"
    elif [[ $url != http* ]]; then
        url="${URL_BASE%/source/}/$url"
    fi
    
    # Extrai apenas o nome do arquivo da URL
    filename=$(basename "$url")
    
    # Usa express√£o regular para extrair a vers√£o
    if [[ $filename =~ Python-(.*).tar.xz ]]; then
        # Captura a parte entre "Python-" e ".tar.xz"
        version="${BASH_REMATCH[1]}"
        
        # Converte vers√£o para formato orden√°vel
        sortable_version=$(echo "$version" | tr '.' ' ')
        
        # Formata sa√≠da: vers√£o orden√°vel + tab + URL
        echo -e "$sortable_version\t$url"
    fi
done < "$temp_links" > "$temp_sorted"

# Ordena numericamente por vers√£o
sort -k1,1n -k2,2n -k3,3n -k4,4n "$temp_sorted" | cut -f2- > "$OUTPUT_FILE"

# Conta arquivos ap√≥s processamento
total_files_after=$(wc -l < "$OUTPUT_FILE")

# Mostra links ordenados ao usu√°rio
echo ""
echo "üìã Lista de links ordenados:"
while IFS= read -r link; do
    echo "  ‚úÖ $link"
done < "$OUTPUT_FILE"

# Remove arquivos tempor√°rios
rm "$temp_links" "$temp_sorted"

# Exibe relat√≥rio final
echo ""
echo "‚úÖ Busca conclu√≠da!"
echo "================================="
echo "üì¶ Arquivos encontrados:    $total_files"
echo "üîß Ap√≥s remover duplicatas: $total_files_after"
echo "üíæ Links salvos em:         $OUTPUT_FILE"
echo "================================="
